{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt, timedelta as tmd\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from importlib import reload\n",
    "import DataLoader.xAPIConnector\n",
    "reload(DataLoader.xAPIConnector)\n",
    "from DataLoader.xAPIConnector import *\n",
    "\n",
    "\n",
    "import DataLoader.DataLoader\n",
    "reload(DataLoader.DataLoader)\n",
    "from DataLoader.DataLoader import *\n",
    "\n",
    "from DataLoader.config import user_id, pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pobieranie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Należy podać listę symboli, datę, od której chcemy zaciągnąć dane i częstotliwość (teraz '5min'). Można też podać datę 'end', ale domyślnie zaciąga się do chwili obecnej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-13 16:15:23.035885] Loguję do API...\n",
      "\tWysyłam zapytanie do API...\n",
      "\tWysyłam zapytanie do API...\n",
      "[2025-01-13 16:15:30.529496] Wylogowuję z API...\n"
     ]
    }
   ],
   "source": [
    "symbols = ['BITCOIN', 'ETHEREUM']\n",
    "start, interval = '2024-12-01 00:00:00', '5min'\n",
    "\n",
    "dl = DataLoader(user_id, pwd)\n",
    "data = dl.getData(symbols=symbols, start_date=start, interval=interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikatory można budować na mnóstwo różnych sposobów. Ogólnie trzeba się zdecydować, na ilu obserwacjach wstecz ma się opierać klasyfikacja. Liczbę tych obserwacji nazwiemy 'window' i przyjmiemy jako parametr.\n",
    "\n",
    "Pierwszy pomysł to klasyfikacja na podstawie stóp zwrotu, klasy również będziemy budować na podstawie stóp zwrotu. Metoda budowania klas zostanie omówiona dalej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = int(60/int(interval[:-3]))\n",
    "returnsBTC = data.loc[:, 'BITCOIN'].pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(data: pd.Series, window: int, skip: int) -> tuple:   \n",
    "    # można ustawić okna zachodzące (0 < skip < window)\n",
    "    # można ustawić niezachodzące (skip >= window)\n",
    "    assert skip > 0, \"Pętla w kodzie nigdy się nie zakończy...\"\n",
    "    \n",
    "    # Generujemy 'okna'\n",
    "    X = pd.DataFrame(columns=range(window))\n",
    "    \n",
    "    i = len(data)\n",
    "    count = 0\n",
    "    while i >= window:\n",
    "        temp_y = data.iloc[i-window:i]\n",
    "        \n",
    "        X.loc[count, :] = temp_y.values\n",
    "        \n",
    "        i = i - skip    \n",
    "        count += 1\n",
    "        \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele klasyfikacyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogR, LinearRegression as LinR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiowanie klas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszy pomysł na zdefiniowanie klas to przyjęcie $1$ jeśli stopa zwrotu jest $>$'threshold' oraz $0$ w p.p.\n",
    "\n",
    "Próg odcięcia można podać jako parametr i już po pierwszych testach widać, że dla prostej klasyfikacji typu \"czy zwrot > $0$\" skuteczność jest około $50\\%$. Im wyższy próg, tym lepsza skuteczność."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasa 0: 75.0027%\n",
      "Klasa 1: 24.9973%\n"
     ]
    }
   ],
   "source": [
    "skip = 1\n",
    "arr = prepareData(data=returnsBTC, window=window, skip=skip)\n",
    "X = arr[:, :-1]\n",
    "y = arr[:, -1]\n",
    "\n",
    "threshold = np.quantile(y, 0.75)\n",
    "y = (y > threshold)*1.0\n",
    "\n",
    "for i in range(0, 2):\n",
    "    print(f\"Klasa {i}: {np.sum(y == i)/len(y):.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz podzielimy dane na treningowe i testowe, po czym sprawdzimy jakość predykcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] W zbiorze treningowym znaduje się 6527 obserwacji.\n",
      "[INFO] W zbiorze testowym znajduje się 2798 obserwacji.\n"
     ]
    }
   ],
   "source": [
    "train_test_ratio = 0.7\n",
    "len_train = int(train_test_ratio*X.shape[0])\n",
    "\n",
    "Xtrain = X[:len_train, :]\n",
    "ytrain = y[:len_train]\n",
    "\n",
    "Xtest = X[len_train:, :]\n",
    "ytest = y[len_train:]\n",
    "\n",
    "print(f\"[INFO] W zbiorze treningowym znaduje się {Xtrain.shape[0]} obserwacji.\")\n",
    "print(f\"[INFO] W zbiorze testowym znajduje się {Xtest.shape[0]} obserwacji.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Regresja logistyczna\n",
      "\tSkuteczność treningowa modelu: 76.3138%\n",
      "\tSkuteczność testowa modelu: 71.9442%\n"
     ]
    }
   ],
   "source": [
    "print(f\"[INFO] Regresja logistyczna\")\n",
    "clf = LogR().fit(Xtrain, ytrain)\n",
    "print(f\"\\tSkuteczność treningowa modelu: {clf.score(Xtrain, ytrain):.4%}\")\n",
    "print(f\"\\tSkuteczność testowa modelu: {clf.score(Xtest, ytest):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Support Vector Machines\n",
      "\tSkuteczność treningowa modelu: 77.9838%\n",
      "\tSkuteczność testowa modelu: 70.8006%\n"
     ]
    }
   ],
   "source": [
    "print(f\"[INFO] Support Vector Machines\")\n",
    "clf = SVC(kernel='poly').fit(Xtrain, ytrain)\n",
    "print(f\"\\tSkuteczność treningowa modelu: {clf.score(Xtrain, ytrain):.4%}\")\n",
    "print(f\"\\tSkuteczność testowa modelu: {clf.score(Xtest, ytest):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Drzewo decyzyjne\n",
      "\tSkuteczność treningowa modelu: 76.6662%\n",
      "\tSkuteczność testowa modelu: 71.8013%\n"
     ]
    }
   ],
   "source": [
    "print(f\"[INFO] Drzewo decyzyjne\")\n",
    "clf = DTC(max_depth=3).fit(Xtrain, ytrain)\n",
    "print(f\"\\tSkuteczność treningowa modelu: {clf.score(Xtrain, ytrain):.4%}\")\n",
    "print(f\"\\tSkuteczność testowa modelu: {clf.score(Xtest, ytest):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Las decyzyjny\n",
      "\tSkuteczność treningowa modelu: 83.9896%\n",
      "\tSkuteczność testowa modelu: 69.0136%\n"
     ]
    }
   ],
   "source": [
    "print(f\"[INFO] Las decyzyjny\")\n",
    "clf = GBC(n_estimators=100, max_depth=5).fit(Xtrain, ytrain)\n",
    "print(f\"\\tSkuteczność treningowa modelu: {clf.score(Xtrain, ytrain):.4%}\")\n",
    "print(f\"\\tSkuteczność testowa modelu: {clf.score(Xtest, ytest):.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predykcje uzyskane przy użyciu tych metod tworzenia $y$ dają rezultaty gorsze od naiwnego klasyfikatora przypisującego zawsze $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inne pomysły na definiowanie klas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomysł oparty na regresji liniowej\n",
    "\n",
    "$$y_t = \\beta_0 + \\beta_{-5}y_{t-5} + ... + \\beta_{-1}y_{t-1} + \\beta_1y_{t+1} + ... +\\beta_5y_{t+5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 11\n",
    "skip = window\n",
    "\n",
    "arr = prepareData(data=returnsBTC, window=window, skip=skip)\n",
    "X = np.delete(arr, 5, axis=1)\n",
    "y = arr[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01991393, -0.04023283, -0.03274852,  0.05045935,  0.02898242,\n",
       "       -0.08376527, -0.04969022,  0.0946578 , -0.00211609,  0.07973739])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinR().fit(X, y)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006519796843450826"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
